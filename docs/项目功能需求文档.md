# 项目背景：

**基于LangChain的本地化RAG问答系统**

基于Langchain框架实现的基于本地知识库的RAG问答应用，核心痛点在于解决通用大模型在特定领域知识上的幻觉问题，同时满足数据隐私和网络环境限制的需求。

**项目目标：**

1. 建立一套对**中文场景**友好、支持​**开源模型**​、且**可离线运行**的知识库问答系统。
2. 提供从模型部署、知识库管理到用户交互的一站式解决方案，对外提供 WebUI 界面及 FastAPI 服务调用。

# **主要功能：**

1. ## 大模型管理与微调：
   
   1. ### 模型接入与部署：
   
   * 支持 **Xinference ​**推理框架，实现大模型的本地化部署。
   * 兼容 **OpenAI**​**​ ​**​**API** 协议，支持接入 GLM-4-Chat、Qwen2.5-7B-Instruct (Int4 量化版)等最新开源模型。
   * ​**多模态支持**​：集成模型Qwen2-VL-7B-Instruct（Int4 量化版）、GLM-4v-9b(Int4 量化版)等多模态大模型，支持“图+文”输入，输出多模态理解结果。
   
   2. ### 模型微调
   
   * 基于 **LlamaFactory** 框架，支持 PEFT/LoRA 等高效微调技术，使模型适配特定领域知识。
   * 集成 **Swanlab** 工具，提供可视化的训练过程跟踪与指标监控。
   * 微调后的模型支持一键通过 Xinference 重新部署上线。
2. ## 检索增强生成（RAG）：

**​RAG基础流程：​**加载文件 -> 读取文本 -> 文本分割 -> 文本向量化 -> 用户提问向量化 -> 在文本向量中匹配出与问句向量最相似的 `top k`个 -> 匹配出的文本作为上下文和问题一起添加到 `prompt`中 -> 提交给 `LLM`生成回答。

1. ### 知识库与文档处理

负责将非结构化数据转化为机器可理解的向量数据。

​**多格式文档加载**​：

* 支持 Markdown, PDF, Word, PPT 等常规文档，支持图片 OCR 识别、结构化 CSV 过滤加载。
* ​**自动化流水线**​：实现“加载 -> 文本切分 -> 向量化 -> 写入向量库”的一站式自动化处理。

​**文档分块**​：

* ​**基础切分**​：作为默认策略，基于分隔符递归分割文本。
* ​**语义切分**​：基于ai模型进行语义切分。
* 支持​**长文档摘要分块管理**​，提取大纲用于快速检索，优化长文理解效果。
  * ​**切分两份**​：将文档同时切分为“小块”（Child chunks，如 200 token）和“大块”（Parent chunks，如 2000 token 或整页）。
  * ​**小块检索，大块生成**​：向量化存储仅针对“小块”进行（更精准匹配细节）；但在检索召回时，通过 ID 映射返回对应的“大块”给 LLM。

​**向量库与存储管理**​：负责 RAG 系统中“向量化数据的持久化存储、索引维护与检索”。

* ​**向量库**​：Chroma【轻量级/本地】。
* 将 Chroma 实例统一转换为 LangChain 的 `Retriever` 接口。
* ​**检索参数透传​**​：支持动态调整 `k` 值（返回数量）；支持 `score_threshold`（相似度阈值），在本地库中直接过滤掉低相关性的噪声。
* 支持知识库的创建/删除、文档的增删改查、以及索引重建。

​**Embedding 模型管理**​：

* 封装统一接口，支持本地 Embedding 模型（如 bge-large-zh、Qwen3-text-embedding-8B）的调用与切换。

2. ### 检索增强生成引擎

负责精准找到相关信息并生成回答。

**​查询优化 (​**​**Query**​​ ​​​**Rewrite**​)

* ​**智能改写**​：针对用户提问模糊、语义缺失（如“它怎么收费？”中的“它”指代不明）的情况，系统会自动利用大模型将问题重写为语义清晰、关键词明确的查询语句，从而提升检索命中率。
* **鲁棒性**​​**设计**​：具备自动降级机制，若改写服务响应超时，系统将自动回退使用用户的原始提问进行检索，保证问答速度和稳定性。

**多策略检索(Retrieval)：**

* ​**语义检索**​：基于向量相似度，支持配置 Top-K 和相似度阈值 (`score_threshold`) 。
* ​**关键词检索**​：集成 Jieba 分词，支持基于 BM25 的传统文本评分检索。
* ​**混合检索**​：融合向量检索与 BM25 结果，兼顾语义相似度和关键词精确匹配。

​**重排序 (Rerank)**：

* 引入 **BGE-Reranker** 模型，对初步召回的候选文档进行二次精排，显著提升上下文相关性。

**对话编排：**

* ​**Prompt 构造​**​：动态组装 “系统提示词 + 检索到的文档片段 + 历史对话记录 + 用户问题”
* 生成结果包含答案文本及引用文档列表（原文片段），供前端展示“来源片段”。

3. ### RAG自动化评估体系

用于量化回答的准确性（基于​**Ragas 开源评估框架**​）。

**合成数据**​**生成：**

* 针对新导入的知识库，系统支持一键自动生成“问答测试集”。
* 利用大模型模拟用户视角，基于文档内容提出具有不同难度（推理、多跳、条件限制）的问题，并生成标准答案，作为系统的“模拟考题”。

​**多维质量评分**​：

* 系统内置自动化评分机制，无需人工逐条检查，即可从以下维度对 RAG 效果进行打分：
  * ​**检索质量**​：评估系统是否准确找到了相关文档（解决“找不到”的问题）。
  * ​**生成质量**​：评估 AI 回答是否忠实于原文、是否存在幻觉（解决“乱回答”的问题）。

提供量化的评估报告，帮助开发者直观判断当前使用的 Embedding 模型、切分策略（Chunk Size）或 LLM 是否适合当前知识库，从而进行针对性调整。

3. ## 用户交互界面与接口设计：

基于 **Streamlit** 构建轻量级前端，提供可视化的操作环境。

**知识库管理台：**

* 文件上传区（支持拖拽）。
* 知识库列表管理（新建、删除、选择向量库类型）。
* 文档切分参数配置（Chunk Size, Overlap）。

**智能问答窗口：**

* 对话气泡展示（区分用户与 AI）。
* ​**参数侧边栏**​：实时调整检索模式（混合/语义）、Top-K 值、阈值、模型温度等。
* ​**调试与评估模式**​：
  * ​**实时评估开关**​：提供一个“开启 Ragas 实时评分”的 Toggle 开关（默认关闭）。
  * ​**功能描述**​：开启后，系统在生成回答的同时，会在后台调用评估模型对本次问答质量进行打分。
  * ​**结果展示**​：在 AI 回答结束后，在对话气泡下方额外展示 `Faithfulness`（忠实度）和 `Context Recall`（召回率）的具体分值，辅助开发者判断当前检索效果。
* ​**源文档展示区**​：点击回答中的引用角标，展开显示对应的源文档片段。

**API**​**服务：**

* 基于 **FastAPI** 封装后端逻辑，提供符合 RESTful 标准的 API。
* 核心接口：`/v1/chat/completions` (兼容 OpenAI), `/kb/upload`, `/kb/search`。

